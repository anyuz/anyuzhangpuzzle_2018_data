# anyuzhangpuzzle_2018


## Table of Contents
1. [Implementation details](README.md#implementation-details)
2. [Test of Format](README.md#test-of-format)
3. [My input files](README.md#my-input-files)
4. [My output file](README.md#my-output-file)

## Implementation details



## Test of Format 

Pass test_1  

The result generated by my sessionization.py is exactly same as the file saved in the test output.
In the processing of generating sessionization.txt, I found the datasets from website varies in the format of time. 
The test_1 provide us time format as 2017-06-30 ,but onine log.csv 's time format is 12/31/03.  

## My tests

### Log.csv

From the website SEC weblogs I can access to a lot of datasets, I picked sample datasets at one day from 2003 to 2017. The datasets varied a lot from 106kB to 2.78GB, which is beneficial to checking the performance of my sessionization.py on small and large datasets. But the git hub only allow me upload files smaller than 25 MB. So what you can access in tests folder are just small datasets.

### inactivity_period.txt

From the details of challange I know the duration is a important value to check if an IP is in a session of a single web page document request. The value will range from 1 to 86,400 (i.e., one second to 24 hours). In the given test example, the duration time is 2 seconds. By increasing the duration time : 2 seconds , 3seconds and 100 seconds, the computing time of output file increased also. 
By setting the period of inactivity to 5 seconds, with same log.csv in the test_1, the output is changed as following:

    101.81.133.jja,2017-06-30 00:00:00,2017-06-30 00:00:00,1,1
    107.23.85.jfd,2017-06-30 00:00:00,2017-06-30 00:00:03,4,4
    108.91.91.hbc,2017-06-30 00:00:01,2017-06-30 00:00:04,4,2
    106.120.173.jie,2017-06-30 00:00:02,2017-06-30 00:00:02,1,1
    107.178.195.aag,2017-06-30 00:00:02,2017-06-30 00:00:04,3,2
    
As I changed the period of inactivity time to 5 seconds, two sessions of 108.91.91.hbc combined to one session. 

## Optimization of sessionization.py 

With a large dataset in 2017, which size is 2.78GB, the computating time is as long as more than 20 mins in the first version of my sessionization.py. It is too long to be a applicable program. So I made changes like following:






    For checking the performence of optimized sessionization method, I used the 455.9MB dataset in 06/29/2011 with 100s duration time. 
    original                          optimized 
    real	6m3.742s                  real	3m17.475s
    user	6m0.968s                  real	3m17.475s
    sys	0m1.282s                  sys	0m1.084s



